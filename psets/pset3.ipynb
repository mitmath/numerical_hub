{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08cd437b",
   "metadata": {},
   "source": [
    "# 18.C21 Problem Set 3\n",
    "\n",
    "Due **Thursday** 2/26 at **midnight**.  Submit in PDF format.  For handwritten solutions, use a decent-quality scan/image (e.g. get a scanner app on your phone or use a tablet).  For computational results, submit a PDF printout of your Jupyter notebook showing your code and (clearly labeled) results.  Combine all your submissions into a single PDF file.\n",
    "\n",
    "**TO GENERATE A PDF OF A JUPYTER NOTEBOOK:** In the Jupyter client (e.g. the [JupyterLab Desktop](https://github.com/jupyterlab/jupyterlab-desktop) app), in the File pull-down menu, select Save and Export Notebook As, and then select the HTML format (not PDF, which may require special software). Then open the downloaded HTML file with your favorite browser, and use the browser's Print function to generate the PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53b289",
   "metadata": {},
   "source": [
    "## Problem 1 (5+5+5+5 points) \n",
    "\n",
    "This problem concerns two different analogues of *piecewise-linear* functions in *two-dimensions*, for functions $f(\\vec x)$ on $\\vec{x} = (x,y) \\in \\mathbb{R}^2$.\n",
    "\n",
    "**(a)** Suppose that you have three data points on a right triangle: $\\vec{x}_1 = (0,0)$, $\\vec{x}_2 = (1,0)$, and $\\vec{x}_3 = (0,1)$, with corresponding function values $f_i = f(\\vec{x}_i)$ for $i = 1,2,3$.  Derive a formula for the linear (technically \"affine\") interpolant (a plane) $p(\\vec{x})$ that goes through these three points, i.e. $p(\\vec{x}) = c_0 + \\vec{c}^T \\vec{x}$ for some coefficients $c_0,c_1,c_2$ computed from $p(\\vec{x}_i) = f_i$.\n",
    "\n",
    "**(b)** Suppose that we have three *arbitrary* non-collinear points $\\vec{x}_i \\in \\mathbb{R}^2$.  Derive a formula for a matrix $A \\mathbb{R}^{2 \\times 2}$ and a vector $\\vec{b} \\mathbb{R}^2$ such that $A\\vec{x} + \\vec{b}$ maps $\\vec{x}_1, \\vec{x}_2, \\vec{x}_3 \\mapsto (0,0), (1,0), (0,1)$ (it maps an arbitrary triangle onto a \"reference\" triangle).   Explain how you can combine this transformation with your answer from (a) to do linear interpolation from $f_i = f(\\vec{x}_i)$ evaluated on an arbitrary triangle of points $\\vec{x}_1, \\vec{x}_2, \\vec{x}_3$.\n",
    "\n",
    "*Comment*: In [finite-element methods](https://en.wikipedia.org/wiki/Finite_element_method), where space is divided into an arbitrary mesh of triangles/tetrahedras/etcetera \"elements\", this kind of technique allows one to first work out the formulas on a simple \"reference\" element and then map every other element to this reference.\n",
    "\n",
    "**(c)** Suppose that you have *four* data points on a rectangle: $\\vec{x}_1 = (x_1,y_1)$, $\\vec{x}_2 = (x_2,y_1)$, $\\vec{x}_3 = (x_1,y_2)$, and $\\vec{x}_4 = (x_2,y_2)$, with corresponding function values $f_i = f(\\vec{x}_i)$ for $i = 1,2,3,4$.  Form the piecewise linear interpolant $p_1(x)$ on the line segment between $\\vec{x}_1$ and $\\vec{x}_2$ as in class, and the piecewise linear interpolant $p_2(x)$ between $\\vec{x}_3$ and $\\vec{x}_4$.   Now, linearly interpolate the functions $p_1$ and $p_2$ in $y$ to give the formula for a \"bilinear\" interpolation function $p(x,y)$.   Is $z = p(x,y)$ a plane?  Why or why not?\n",
    "\n",
    "**(d)** Suppose you have a 2d grid of points $(x_i, y_j)$ for $i, j = 1, \\ldots, \\ell$ as in class (with $x_i$ and $y_j$ sorted in ascending order), and on *each rectangle* $(x_{i},y_{j}),(x_{i+1},y_{j}),(x_{i},y_{j+1}),(x_{i+1},y_{j+1})$ in the grid you form a bilinear interpolation as in part (c).  This is *piecewise* bilinear interpolation, defining a function $p(x,y)$ everywhere in the grid.  Explain how, for an arbitary grid, you can evaluate $p(x,y)$ in $O(\\log \\ell)$ computational cost (hint: look up \"binary search\"), and for an equispaced grid ($x_i = x_0 + i\\Delta x$ and $y_j = y_0 + j \\Delta y$) you can evaluate $p(x,y)$ in $O(1)$ computational cost.\n",
    "\n",
    "(Technically, this is computational cost in the so-called \"RAM model\" where we assume that looking up $x_i$ or $y_j$ given $i$ or $j$ is $O(1)$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abcd52",
   "metadata": {},
   "source": [
    "## Problem 2 (5+5+5 points)\n",
    "\n",
    "In this problem, you will try out some 2d interpolation algorithms on [\"Franke's function\"](https://www.sfu.ca/~ssurjano/franke2d.html), a common test function for 2d interpolation, and work out their convergence rates:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{franke}(x_1, x_2) =\\;&\n",
    "0.75 \\exp\\!\\left(-0.25 \\left[(9x_1 - 2)^2 + (9x_2 - 2)^2\\right]\\right) \\\\\n",
    "&{} + 0.75 \\exp\\!\\left(-\\frac{(9x_1 + 1)^2}{49} - \\frac{9x_2 + 1}{10}\\right) \\\\\n",
    "&{} + 0.5 \\exp\\!\\left(-0.25 \\left[(9x_1 - 7)^2 + (9x_2 - 3)^2\\right]\\right) \\\\\n",
    "&{} - 0.2 \\exp\\!\\left(-(9x_1 - 4)^2 - (9x_2 - 7)^2\\right).\n",
    "\\end{align}\n",
    "\n",
    "evaluated in a box $x_1 \\in [0,1]$ and $x_2 \\in [0,1]$.\n",
    "\n",
    "Code for this function is given below in Julia and Python/Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1f321a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "franke (generic function with 2 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Julia:To apply it to arrays, use f.(x1, x2)\n",
    "\n",
    "function franke(x1, x2)\n",
    "    return 0.75 * exp(-0.25 * ((9 * x1 - 2)^2 + (9 * x2 - 2)^2)) +\n",
    "           0.75 * exp(-(9 * x1 + 1)^2 / 49 - (9 * x2 + 1) / 10) +\n",
    "           0.5  * exp(-0.25 * ((9 * x1 - 7)^2 + (9 * x2 - 3)^2)) -\n",
    "           0.2  * exp(-(9 * x1 - 4)^2 - (9 * x2 - 7)^2)\n",
    "end\n",
    "\n",
    "# it's convenient to also let x = [x1,x2] be a vector\n",
    "franke(x) = franke(x[1], x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python: inputs x1 and x2 are arrays\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def franke(x1, x2):\n",
    "    x1 = np.asarray(x1)\n",
    "    x2 = np.asarray(x2)\n",
    "\n",
    "    return (\n",
    "        0.75 * np.exp(-0.25 * ((9 * x1 - 2)**2 + (9 * x2 - 2)**2)) +\n",
    "        0.75 * np.exp(-(9 * x1 + 1)**2 / 49 - (9 * x2 + 1) / 10) +\n",
    "        0.5  * np.exp(-0.25 * ((9 * x1 - 7)**2 + (9 * x2 - 3)**2)) -\n",
    "        0.2  * np.exp(-(9 * x1 - 4)**2 - (9 * x2 - 7)**2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c0c48",
   "metadata": {},
   "source": [
    "Now, form various interpolants $p(x_1,x_2)$ for this function and compute the *maximum* error $\\Vert \\text{franke} - p \\Vert_\\infty$ evaluated on a $1000 \\times 1000$ equispaced grid of points in $[0,1] \\times [0,1]$.\n",
    "\n",
    "Plot (on a log-log or semi-log scale as appropriate) this error versus $n$, where $n$ is the number of interpolation points, and indicate whether you observe a power law (which? why?) or exponential convergence.  (Use enough data points to make the dependence clear.)\n",
    "\n",
    "**(a)** Bilinear interpolation from an equispaced grid of $\\ell \\times \\ell$ ($n = \\ell^2$) points.  You can use e.g. [`BasicInterpolators.BilinearInterpolator`](https://markbaum.xyz/BasicInterpolators.jl/dev/2d/#BasicInterpolators.BilinearInterpolator) in Julia [`scipy.interpolate.interp2d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp2d.html) in Python.\n",
    "\n",
    "**(b)** 2d polynomial interpolation from Chebyshev points in $x_1,x_2$.  You can use e.g. [FastChebInterp.jl](https://github.com/JuliaMath/FastChebInterp.jl) in Julia or e.g. `numpy.polynomial.chebyshev.chebfit` (this is 1d, but then you do it twice along both directions) and `numpy.polynomial.chebyshev.chebval2d` in Numpy.\n",
    "\n",
    "**(c)** Using radial basis functions (RBFs) with the Gaussian kernel $\\Phi(\\vec{x}) = \\exp(-\\Vert \\vec{x} \\Vert^2 / R^2)$ at $n$ uniformly chosen *random* points in the square (`x1, x2 = rand(n), rand(n)` in Julia, or `numpy.random.rand` in Numpy).  Choose $R = 1/\\sqrt{n}$ so that it is proportional to the average spacing of the points.  Don't use an RBF library here: implement the \"Vandermonde-like\" matrix and solve for the coefficients yourself.   Instead of the *maximum* error, plot the *root-mean-square* error (again on a $1000\\times 1000$ equispaced grid).  To reduce the noise from the random points, repeat $10$ times for each $n$ and average the error.\n",
    "\n",
    "Note: for RBFs via a Vandermonde matrix, you won't be able to go much past $n=1000$ points before it gets too expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c42fac",
   "metadata": {},
   "source": [
    "## Problem 3 (4+4+4+4 points)\n",
    "\n",
    "(Based on [exercise 5.6.1](https://fncbook.com/integration/#problem-integration-tests) from the FNC book.)\n",
    "\n",
    "Integrate the following functions numerically using *both* the trapezoidal rule and Clenshaw-Curtis quadrature for $n+1$ points, and **plot the relative error versus n** (compared to the exact result provided).  Identify whether it is power-law (which?) or exponential dependence (use a log–log or semi-log scale as appropriate).\n",
    "\n",
    "A function is provided below in both Julia and Python to compute the Clenshaw-Curtis quadrature points $x_k$ and weights $w_k$ for a given length $n$ (supporting even $n$ only) for integration on $[-1,+1]$.  You should implement the trapezoidal rule yourself (it is trivial).\n",
    "\n",
    "**(a)** $\\int_0^1 x \\log(1+x) \\, dx = 1/4$.\n",
    "\n",
    "**(b)** $\\int_0^1 x^2 \\tan^{-1}(x) \\, dx = \\frac{\\pi - 2 + 2\\log 2}{12}$.\n",
    "\n",
    "**(c)** $\\int_0^{\\pi/2} e^x \\cos(x) \\, dx = \\frac{e^{\\pi/2} - 1}{2}$.\n",
    "\n",
    "**(d)** $\\int_0^1 \\sqrt{1 - x^2} \\, dx = \\pi/4$.  Why is this function not so nice, even for Clenshaw–Curtis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996d7ca",
   "metadata": {},
   "source": [
    "The following is Julia and Python code to compute these Clenshaw–Curtis points $x_n$ and weights $w_n$ for any even $n > 0$.  Given `x, w = clenshaw_curtis(n)` and a function $f(x)$, you can then estimate $\\int_{-1}^{+1} f(x) dx$ by `sum(f.(x) .* w)` in Julia and by `numpy.sum(map(f, x) * w)` in Python.\n",
    "\n",
    "You will need to do a change of variables (as in class) to map these to points and weights for an arbitrary integration interval $[a,b]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b8b8b42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clenshaw_curtis (generic function with 1 method)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Julia code:\n",
    "import FFTW\n",
    "function clenshaw_curtis(N)\n",
    "    iseven(N) && N > 0 || throw(ArgumentError(\"this implementation requires even N > 0\"))\n",
    "    x = cos.(range(0, pi, length=N+1)) # Chebyshev points\n",
    "    k = 0:N÷2\n",
    "    d = @. 2 / (1-4k^2) # cosine integrals\n",
    "    w = FFTW.r2r(d, FFTW.REDFT00) / N # type-I DCT\n",
    "    w[1] /= 2\n",
    "    return x, [w; reverse(w[1:end-1])]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code:\n",
    "import numpy as np\n",
    "from scipy.fft import dct\n",
    "def clenshaw_curtis(N):\n",
    "    if N <= 0 or N % 2 != 0:\n",
    "        raise ValueError(\"this implementation requires even N > 0\")\n",
    "    x = np.cos(np.linspace(0, np.pi, N + 1)) # Chebyshev points\n",
    "    k = np.arange(0, N // 2 + 1)\n",
    "    d = 2 / (1 - 4 * k**2) # cosine integrals\n",
    "    w = dct(d, type=1) / N\n",
    "    w[0] /= 2\n",
    "    return x, np.concatenate([w, np.flip(w[0:-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1026e6",
   "metadata": {},
   "source": [
    "## Problem 4 (5+5+5 points)\n",
    "\n",
    "It turns out that the trapezoidal rule (or, equivalently, a simple Riemann sum / rectangle rule) is also quite accurate to compute $\\int_{-\\infty}^{+\\infty} f(x) dx$ for functions $f(x)$ that decay sufficiently rapidly, where you simply truncate the trapezoidal rule when $f(x)$ gets small enough (e.g. when it underflows to zero).  Like periodic functions, this is another case where the trapezoidal/rectangle rule is very accurate, so then the trick is to try to transform arbitrary integrals into this form.\n",
    "\n",
    "We can make almost *any* function on a *finite* interval equivalent to a *rapidly* decaying function on an *infinite* interval by the change of variables:\n",
    "$$\n",
    "\\int_{-1}^{+1} f(x)\\,dx = \\int_{-\\infty}^{+\\infty} f(x(t)) w(t)\\, dt \\, ,\n",
    "$$\n",
    "where $x(t) = \\tanh(\\frac{\\pi}{2} \\sinh t)$ and the Jacobian factor is $w(t) = x'(t) = \\frac{\\pi}{2} \\cosh(t) \\operatorname{sech}^2(\\frac{\\pi}{2} \\sinh t)$.\n",
    "\n",
    "**(a)** Use the trapezoidal rule to numerically integrate $\\int_{-\\infty}^{+\\infty} e^{-x^2} dx = \\sqrt{\\pi}$, truncating the sum when the integrand underflows to `0.0`.  Plot the relative error as a function of the number $n$ of quadrature points (on a log–log or semi-log scale as appropriate), and identify whether the convergence is power-law (which?) or exponential, or perhaps even faster than exponential.\n",
    "\n",
    "**(b)** Consider the function $f(x) = \\sqrt{1-x^2}$, whose exact integral (similat to problem 3d) is $\\int_{-1}^{1} \\sqrt{1-x^2} dx = \\pi/2$.  Plot the transformed integrand $f(x(t)) w(t)$ for $t \\in [-3,3]$ on a semilog scale to see that it is rapidly decaying with $|t|$ as claimed above.  Also include separate curves for $f(x(t))$ and $w(t)$ on the same plot.\n",
    "\n",
    "**(c)** Integrate $\\int_{-\\infty}^{+\\infty} f(x(t))w(t) \\, dt$ for $f(x) = \\sqrt{1-x^2}$ using the trapezoidal rule as in part (a), and plot the relative error (vs. the exact answer $\\pi/2$) versus $n$ on a log-log or semi-log scale as appropriate.  Is the convergence rate a power law (which?), exponential, or…?  How does it compare to Clenshaw-Curtis in part 3(d)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
